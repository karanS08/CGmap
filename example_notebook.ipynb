{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGmap YOLOv8 - Complete Tutorial\n",
    "\n",
    "This notebook demonstrates the complete workflow for crop gap detection using YOLOv8.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Installation\n",
    "2. Data Preparation\n",
    "3. Model Training\n",
    "4. Evaluation\n",
    "5. Inference\n",
    "6. Visualization\n",
    "7. Model Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install ultralytics\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project utilities\n",
    "from utils.data_preprocessing import create_sample_data, validate_dataset\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for demonstration\n",
    "data_dir = project_root / 'data' / 'processed'\n",
    "\n",
    "print(\"Creating sample dataset...\")\n",
    "create_sample_data(data_dir, num_samples=50)\n",
    "\n",
    "print(\"\\nValidating dataset...\")\n",
    "validate_dataset(data_dir, num_classes=2)\n",
    "\n",
    "print(\"\\n✓ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "import cv2\n",
    "\n",
    "train_images = sorted((data_dir / 'train' / 'images').glob('*.jpg'))[:4]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, img_path in enumerate(train_images):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f\"Sample {idx+1}: {img_path.name}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "We'll train a YOLOv8 nano model for quick demonstration. For better results, use yolov8s/m/l with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Model type: YOLOv8 Nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Note: This is a minimal example with 3 epochs. For real training, use 100+ epochs\n",
    "\n",
    "results = model.train(\n",
    "    data=str(project_root / 'configs' / 'data.yaml'),\n",
    "    epochs=3,  # Use 100+ for real training\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    device='cpu',  # Change to 0 for GPU\n",
    "    project='results',\n",
    "    name='notebook_train',\n",
    "    exist_ok=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "results_dir = Path('results/notebook_train')\n",
    "\n",
    "# Show results plot\n",
    "if (results_dir / 'results.png').exists():\n",
    "    display(Image(filename=str(results_dir / 'results.png')))\n",
    "else:\n",
    "    print(\"Training results plot not available yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    model = YOLO(str(best_model_path))\n",
    "    print(f\"Loaded model: {best_model_path}\")\n",
    "else:\n",
    "    print(\"Best model not found, using last trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "metrics = model.val()\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"  mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.p.mean():.4f}\")\n",
    "print(f\"  Recall: {metrics.box.r.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix_path = results_dir / 'confusion_matrix.png'\n",
    "\n",
    "if confusion_matrix_path.exists():\n",
    "    display(Image(filename=str(confusion_matrix_path)))\n",
    "else:\n",
    "    print(\"Confusion matrix not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference\n",
    "\n",
    "Run the model on new images to detect crop gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on validation images\n",
    "val_images_dir = data_dir / 'val' / 'images'\n",
    "\n",
    "results = model.predict(\n",
    "    source=str(val_images_dir),\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project='results',\n",
    "    name='notebook_predict',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} images\")\n",
    "print(f\"Results saved to: results/notebook_predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction results\n",
    "predict_dir = Path('results/notebook_predict')\n",
    "predicted_images = sorted(predict_dir.glob('*.jpg'))[:4]\n",
    "\n",
    "if predicted_images:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, img_path in enumerate(predicted_images):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"Prediction {idx+1}\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No prediction images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions\n",
    "total_detections = sum(len(r.boxes) for r in results)\n",
    "avg_confidence = np.mean([box.conf.cpu().numpy() for r in results for box in r.boxes]) if results else 0\n",
    "\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"  Total images: {len(results)}\")\n",
    "print(f\"  Total detections: {total_detections}\")\n",
    "print(f\"  Avg detections per image: {total_detections / len(results) if results else 0:.2f}\")\n",
    "print(f\"  Average confidence: {avg_confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Visualize training curves and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves from CSV\n",
    "import pandas as pd\n",
    "\n",
    "results_csv = results_dir / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    if 'train/box_loss' in df.columns:\n",
    "        axes[0].plot(df['epoch'], df['train/box_loss'], label='Box Loss', marker='o')\n",
    "        axes[0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss', marker='s')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Training Losses')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # mAP curves\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@50', marker='o', linewidth=2)\n",
    "        if 'metrics/mAP50-95(B)' in df.columns:\n",
    "            axes[1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@50-95', marker='s', linewidth=2)\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('mAP')\n",
    "        axes[1].set_title('Mean Average Precision')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Results CSV not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Export\n",
    "\n",
    "Export the trained model to different formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format\n",
    "try:\n",
    "    onnx_path = model.export(format='onnx', imgsz=640)\n",
    "    print(f\"✓ Model exported to: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Set up the environment and loaded dependencies\n",
    "2. Created and validated a sample dataset\n",
    "3. Trained a YOLOv8 model for crop gap detection\n",
    "4. Evaluated model performance\n",
    "5. Ran inference on new images\n",
    "6. Visualized results and metrics\n",
    "7. Exported the model for deployment\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Train with your own UAV imagery\n",
    "- Experiment with different model sizes (yolov8s, yolov8m, yolov8l)\n",
    "- Adjust hyperparameters for better performance\n",
    "- Deploy the model on edge devices\n",
    "- Integrate with geospatial workflows\n",
    "\n",
    "For more information, see:\n",
    "- [README.md](README.md)\n",
    "- [QUICKSTART.md](QUICKSTART.md)\n",
    "- [DOCUMENTATION.md](DOCUMENTATION.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
